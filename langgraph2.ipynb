{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3b8fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb0831",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = 'YOUR_GROQ_API_KEY'\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3edcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    sentiment: str\n",
    "\n",
    "# 1. Preprocessing Node\n",
    "def preprocess(state: State) -> State:\n",
    "    cleaned = state[\"messages\"][-1].content.strip()\n",
    "    state[\"messages\"][-1].content = cleaned\n",
    "    return state\n",
    "\n",
    "# 2. Sentiment Analysis Node\n",
    "def analyze_sentiment(state: State) -> State:\n",
    "    msg = state[\"messages\"][-1].content\n",
    "    state[\"sentiment\"] = \"positive\" if \"good\" in msg else \"neutral\"\n",
    "    return state\n",
    "\n",
    "# 3. Chatbot Node\n",
    "def chatbot(state: State) -> State:\n",
    "    return {\"messages\": llm.invoke(state['messages'])}\n",
    "\n",
    "# 4. Logging Node\n",
    "def logger(state: State) -> State:\n",
    "    print(f\"LOG: {state['messages'][-1].content}, Sentiment: {state.get('sentiment')}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5392224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2d32393a120>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"preprocess\", preprocess)\n",
    "builder.add_node(\"analyze_sentiment\", analyze_sentiment)  # renamed\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_node(\"logger\", logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4343633f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2d32393a120>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define flow\n",
    "builder.add_edge(START, \"preprocess\")\n",
    "builder.add_edge(\"preprocess\", \"analyze_sentiment\")  # renamed\n",
    "builder.add_edge(\"analyze_sentiment\", \"chatbot\")     # renamed\n",
    "builder.add_edge(\"chatbot\", \"logger\")\n",
    "builder.add_edge(\"logger\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8eca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e16269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: I understand! Is there anything specific you'd like me to do with this test message? \n",
      "\n",
      "For example, would you like me to:\n",
      "\n",
      "* **Analyze the sentiment?** (I can tell you if it's positive, negative, or neutral)\n",
      "* **Rewrite it in a different style?** (e.g., more formal, more casual)\n",
      "* **Translate it into another language?**\n",
      "* **Generate a response?**\n",
      "\n",
      "\n",
      "Let me know how I can help! ðŸ˜Š  \n",
      "\n",
      ", Sentiment: positive\n",
      "Final State: {'messages': [HumanMessage(content='This is a good test message.', additional_kwargs={}, response_metadata={}, id='52a3fd9b-b62b-4253-bfab-bec666c94a66'), AIMessage(content=\"I understand! Is there anything specific you'd like me to do with this test message? \\n\\nFor example, would you like me to:\\n\\n* **Analyze the sentiment?** (I can tell you if it's positive, negative, or neutral)\\n* **Rewrite it in a different style?** (e.g., more formal, more casual)\\n* **Translate it into another language?**\\n* **Generate a response?**\\n\\n\\nLet me know how I can help! ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 16, 'total_tokens': 125, 'completion_time': 0.198181818, 'prompt_time': 0.00125467, 'queue_time': 0.256743649, 'total_time': 0.199436488}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--fc40c9a3-fabd-46fa-b39d-2be1e6443c7f-0', usage_metadata={'input_tokens': 16, 'output_tokens': 109, 'total_tokens': 125})], 'sentiment': 'positive'}\n",
      "Chatbot's response: I understand! Is there anything specific you'd like me to do with this test message? \n",
      "\n",
      "For example, would you like me to:\n",
      "\n",
      "* **Analyze the sentiment?** (I can tell you if it's positive, negative, or neutral)\n",
      "* **Rewrite it in a different style?** (e.g., more formal, more casual)\n",
      "* **Translate it into another language?**\n",
      "* **Generate a response?**\n",
      "\n",
      "\n",
      "Let me know how I can help! ðŸ˜Š  \n",
      "\n",
      "\n",
      "Detected Sentiment: positive\n",
      "LOG: I understand. \n",
      "\n",
      "Is there anything else I can help you with?\n",
      ", Sentiment: neutral\n",
      "Final State 2: {'messages': [HumanMessage(content='This is a neutral message.', additional_kwargs={}, response_metadata={}, id='39a9dbf0-8966-4a28-bf50-8e72e72d4ac5'), AIMessage(content='I understand. \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 15, 'total_tokens': 33, 'completion_time': 0.032727273, 'prompt_time': 0.00126254, 'queue_time': 0.256642939, 'total_time': 0.033989813}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f03f4623-b75c-49f4-a852-0c4c20d1c85f-0', usage_metadata={'input_tokens': 15, 'output_tokens': 18, 'total_tokens': 33})], 'sentiment': 'neutral'}\n",
      "Chatbot's response 2: I understand. \n",
      "\n",
      "Is there anything else I can help you with?\n",
      "\n",
      "Detected Sentiment 2: neutral\n"
     ]
    }
   ],
   "source": [
    "# Invoke the graph\n",
    "input_message = \"This is a good test message.\"\n",
    "final_state = graph.invoke({\"messages\": (\"user\", input_message)})\n",
    "\n",
    "# Print the final state\n",
    "print(\"Final State:\", final_state)\n",
    "print(\"Chatbot's response:\", final_state['messages'][-1].content)\n",
    "print(\"Detected Sentiment:\", final_state['sentiment'])\n",
    "\n",
    "input_message_2 = \"This is a neutral message.\"\n",
    "final_state_2 = graph.invoke({\"messages\": (\"user\", input_message_2)})\n",
    "print(\"Final State 2:\", final_state_2)\n",
    "print(\"Chatbot's response 2:\", final_state_2['messages'][-1].content)\n",
    "print(\"Detected Sentiment 2:\", final_state_2['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccea9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de413f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f2299f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8849e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
